{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e20263-f140-413c-90c3-e23defa20ae4",
   "metadata": {},
   "source": [
    "#### Marc Stamp - Assessment 4 Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1bf22-959f-468c-ba17-fb72b4e84a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "import numpy as np\n",
    "import pickle \n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.applications as ka\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa4c02-40e5-4e23-a36b-8b0d289d6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "height  = 410\n",
    "width = 280\n",
    "\n",
    "VGG = VGG16(weights='imagenet', include_top = False, input_shape = (height, width, 3))\n",
    "VGG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d139d0-3aa5-488f-ba7e-d34a4cea1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to all txt files in setup - apply same O-H encoding and then save output as csv \n",
    "\n",
    "all_dict = {}\n",
    "\n",
    "foldername = '../groundtruth/'\n",
    "\n",
    "for s in os.listdir(foldername):\n",
    "    #print(s)\n",
    "    if s in ['1981.txt', '1980.txt']:\n",
    "        enc = 'utf-8'\n",
    "    else: \n",
    "        enc = 'utf-16'\n",
    "    #    continue\n",
    "        \n",
    "    \n",
    "    filename = foldername + s\n",
    "    #print(filename)\n",
    "    with open(filename, encoding=enc) as fh:\n",
    "    \n",
    "        for l in fh: # issue with looping through file\n",
    "\n",
    "            str_val = l.strip().split(':', 1)\n",
    "\n",
    "            if (len(str_val) == 1) & (str_val[0] == '{'):\n",
    "                film_dict = {}\n",
    "            elif (len(str_val) == 1) & (str_val[0] == '}'):\n",
    "\n",
    "                #print({film_dict['imdbID'] : film_dict['Genre']})\n",
    "                all_dict[film_dict['imdbID']] = film_dict['Genre']\n",
    "            elif (len(str_val) == 2):\n",
    "                key = str_val[0]\n",
    "                value = str_val[1]\n",
    "                film_dict[key.replace(\"\\\"\", \"\").strip()] = value.replace(\"\\\"\", \"\").replace(\",\", \"\").strip()\n",
    "    \n",
    "\n",
    "all_genres = pd.DataFrame({'id': [], 'genres': []})\n",
    "all_genres\n",
    "for ids, genres in all_dict.items():\n",
    "    genre_list = genres.split()\n",
    "    ids_list = [ids] * len(genre_list)\n",
    "    all_genres = pd.concat([all_genres, pd.DataFrame({'id': ids_list, 'genres': genre_list})])\n",
    "\n",
    "all_genres.reset_index(drop = True, inplace = True)\n",
    "\n",
    "onehotencoder = OneHotEncoder() \n",
    "\n",
    "ohf = onehotencoder.fit(all_genres[['genres']])\n",
    "genre_widen = pd.DataFrame(ohf.transform(all_genres[['genres']]).toarray(),columns = ohf.categories_)\n",
    "genre_widen.drop(['N/A'], axis = 1, inplace = True)\n",
    "\n",
    "genres_widened = pd.concat([all_genres['id'], genre_widen], axis = 1)\n",
    "genres_widened = genres_widened.groupby('id', as_index=False).sum()\n",
    "genres_widened.columns = [(lambda x : x if (x[0] == 'i')  else x[0])(x) for x in genres_widened.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5430c6-ecbd-46f6-8783-707f8c4810c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get order in which to provide labels - alphanumeric order \n",
    "rootdir = '../Movie_Poster_Dataset/'\n",
    "\n",
    "walk_files = []\n",
    "\n",
    "for i in os.walk(rootdir):\n",
    "    #print(i)\n",
    "    walk_files.append(i)\n",
    "    \n",
    "order_files = []\n",
    "\n",
    "for n in range(len(walk_files)):\n",
    "    if n == 0:\n",
    "        continue\n",
    "    \n",
    "    files = walk_files[n][2]\n",
    "    order_files += files\n",
    "    \n",
    "ids = genres_widened['id']\n",
    "ids\n",
    "genre_order_index = [ids[ids == x.replace('.jpg','')].index[0] for x in order_files]\n",
    "genre_order_index\n",
    "\n",
    "ordered_array = np.array(genre_widen.iloc[genre_order_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf8022-4f6d-4e2d-9b07-7896cd10088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_genre_train = image_dataset_from_directory(directory = rootdir,\n",
    "                            labels=list(ordered_array),\n",
    "                            color_mode=\"rgb\",\n",
    "                            validation_split=0.15,\n",
    "                            subset = 'training',\n",
    "                            seed = 1234,\n",
    "                            batch_size=32,\n",
    "                            image_size=(height, width),\n",
    "                            )\n",
    "\n",
    "img_genre_valid = image_dataset_from_directory(directory = rootdir,\n",
    "                            labels=list(ordered_array),\n",
    "                            color_mode=\"rgb\",\n",
    "                            validation_split=0.15,\n",
    "                            subset = 'validation',\n",
    "                            seed = 1234,\n",
    "                            batch_size=32,\n",
    "                            image_size=(height, width),\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200d2f33-b3eb-46bd-bdca-e1651813aa03",
   "metadata": {},
   "source": [
    "#### VGG Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6894539c-1ba7-42c4-a1af-cc400068b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dropout, Dense, Flatten\n",
    "from keras import Input, Model\n",
    "\n",
    "inputs = Input(shape=(410,280, 3))\n",
    "\n",
    "VGG_ = VGG(inputs, training=False)\n",
    "\n",
    "flat = Flatten()\n",
    "\n",
    "VGG_ = flat(VGG_)\n",
    "\n",
    "# first FC layer\n",
    "d1 = Dense(128, activation=\"relu\")\n",
    "VGG_ = d1(VGG_)\n",
    "\n",
    "drp1 = Dropout(0.5)\n",
    "\n",
    "VGG_ = drp1(VGG_)\n",
    "\n",
    "# second FC layer\n",
    "d2 = Dense(128, activation=\"relu\")\n",
    "VGG_ = d2(VGG_)\n",
    "\n",
    "drp2 = Dropout(0.5)\n",
    "\n",
    "VGG_ = drp2(VGG_)\n",
    "\n",
    "# output layer\n",
    "output_layer = Dense(27, activation=\"sigmoid\")\n",
    "output = output_layer(VGG_)\n",
    "\n",
    "VGG_model = Model(inputs, output)\n",
    "\n",
    "VGG_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac2b33e-f42a-4ddc-9102-a2bc7fc17f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark some layers as not trainable\n",
    "training_list = ['input_1','flatten','dense','dropout','dense_1','dropout_1','dense_2']\n",
    "\n",
    "for l in VGG_model.layers:\n",
    "    \n",
    "    if l.name in training_list:\n",
    "        continue\n",
    "    else:\n",
    "        #print(l.name)\n",
    "        VGG_model.get_layer(l.name).trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799bab1e-be3c-4a13-ab96-5f8228867a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c6a9cf-ad12-45c0-a91f-f2578c238165",
   "metadata": {},
   "source": [
    "#### Apply Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1afcb6-ebd3-41ba-a1a9-dbf3393aa568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new method - from data flow\n",
    "epochs = 5\n",
    "\n",
    "VGG_model.fit(img_genre_train, epochs=epochs, validation_data=img_genre_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a7d33a-f7a7-4e3e-bbf2-c579e034746a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
